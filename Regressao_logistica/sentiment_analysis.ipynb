{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Introdu√ß√£o\n",
        "\n",
        "Este notebook apresenta um projeto de **Processamento de Linguagem Natural (NLP)** com foco na **an√°lise de sentimentos em tweets**, utilizando um conjunto de dados rotulado da biblioteca **NLTK**. O objetivo √© construir um pipeline completo de classifica√ß√£o de sentimentos, passando pelas etapas de limpeza dos textos, extra√ß√£o de caracter√≠sticas, treinamento e avalia√ß√£o de um modelo de **Regress√£o Log√≠stica**.\n",
        "\n",
        "---\n",
        "\n",
        "## Etapas do Projeto\n",
        "\n",
        "### Parte 1 - Importa√ß√£o e explora√ß√£o do dataset\n",
        "\n",
        "* Carregamento dos tweets com sentimentos positivos e negativos usando os recursos do NLTK.\n",
        "* An√°lise inicial para entender o formato e a distribui√ß√£o dos dados.\n",
        "\n",
        "### Parte 2 - Pr√©-processamento dos textos\n",
        "\n",
        "* Limpeza dos tweets (remo√ß√£o de men√ß√µes, URLs, hashtags, pontua√ß√£o e s√≠mbolos).\n",
        "* Tokeniza√ß√£o, remo√ß√£o de stopwords e aplica√ß√£o de **stemming** para padroniza√ß√£o das palavras.\n",
        "\n",
        "### Parte 3 - An√°lise de frequ√™ncia\n",
        "\n",
        "* Contagem das palavras mais frequentes associadas a sentimentos positivos e negativos.\n",
        "* Cria√ß√£o de um dicion√°rio de frequ√™ncias para alimentar o modelo de classifica√ß√£o.\n",
        "\n",
        "### Parte 4 - Regress√£o log√≠stica\n",
        "\n",
        "* Implementa√ß√£o da fun√ß√£o sigmoide, da fun√ß√£o de custo e do algoritmo de **gradiente descendente**.\n",
        "* Defini√ß√£o do vetor de caracter√≠sticas para cada tweet.\n",
        "\n",
        "### Parte 5 - Treinamento do modelo\n",
        "\n",
        "* Aplica√ß√£o do gradiente descendente para aprender os pesos (theta) do modelo.\n",
        "* Exibi√ß√£o do custo final e dos pesos ajustados ap√≥s o treinamento.\n",
        "\n",
        "### Parte 6 - Testando o modelo\n",
        "\n",
        "* Cria√ß√£o da fun√ß√£o para prever o sentimento de um novo tweet com base nos pesos aprendidos.\n",
        "* Utiliza√ß√£o da fun√ß√£o `predicao_tweet()` para estimar a probabilidade de sentimento positivo.\n",
        "\n",
        "### Parte 7 - Verificar o desempenho usando o conjunto de teste\n",
        "\n",
        "* Avalia√ß√£o do modelo em dados n√£o vistos.\n",
        "* C√°lculo da **acur√°cia** com base nas previs√µes feitas no conjunto de teste.\n",
        "\n",
        "### Parte 8 - Teste seu pr√≥prio tweet\n",
        "\n",
        "* C√©dula simples para o usu√°rio inserir seu pr√≥prio tweet e obter a previs√£o de sentimento feita pelo modelo.\n"
      ],
      "metadata": {
        "id": "2M_iivNHM9ys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importa√ß√£o das bibliotecas necess√°rias para cria√ß√£o do projeto"
      ],
      "metadata": {
        "id": "KUIBdHWAOWKN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "QpqkM9t_Ms5P"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import twitter_samples\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 1 - Importa√ß√£o e explora√ß√£o do dataset"
      ],
      "metadata": {
        "id": "IRREGnYNO-yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('twitter_samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVQxBrvdOVum",
        "outputId": "827d07d3-cef5-44fb-ac0e-2097666b5470"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "metadata": {
        "id": "RLi5DRgHPahs"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Numeros de tweets positivos: \" , len(all_positive_tweets))\n",
        "print(\"Numeros de tweets negativos: \", len(all_negative_tweets) )\n",
        "\n",
        "print(\"O tipo das variaveis 'all_positive_tweets/all_negative_tweets': \", type(all_positive_tweets))\n",
        "print('O tipo dos objetos(tweets) dentro dessas variaveis ', type(all_positive_tweets[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZIyPcbXPd9D",
        "outputId": "096236ec-7a77-4882-fe46-a0ea62371a2b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeros de tweets positivos:  5000\n",
            "Numeros de tweets negativos:  5000\n",
            "O tipo das variaveis 'all_positive_tweets/all_negative_tweets':  <class 'list'>\n",
            "O tipo dos objetos(tweets) dentro dessas variaveis  <class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printando positivo em verde\n",
        "print('\\033[92m' + all_positive_tweets[np.random.randint(0,5000)])\n",
        "\n",
        "# printando negativo em vermelho\n",
        "print('\\033[91m' + all_negative_tweets[np.random.randint(0,5000)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPb88EiSQwEf",
        "outputId": "ca1facf6-cb41-4927-b7ff-c05a7687adfe"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mAn apartment makeover? http://t.co/ctLa1jppdb great ideas for factory living :)\n",
            "\u001b[91mdidnt took photos with you :-(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Parte 2 Pr√©-processamento dos textos"
      ],
      "metadata": {
        "id": "6Bi6BpjXRMCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re                                  # library for regular expression operations\n",
        "import string                              # for string operations"
      ],
      "metadata": {
        "id": "-v4vMO3DRxln"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para essa parte utilizaremos steamming, remo√ß√£o de stop words e tokeniza√ß√£o das palavras, utilizaremos um tweet aleatorio como exemplo para ilustrar cada parte do processo"
      ],
      "metadata": {
        "id": "iRKZTygPRU7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = all_positive_tweets[2277]\n",
        "print(tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGXL2BjKRSG3",
        "outputId": "7cd656ac-1d92-4c3e-bc12-197615aba0c9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off‚Ä¶ https://t.co/3tfYom0N1i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTCbaQRfRrRA",
        "outputId": "5d8dce7d-77a8-4af0-a25c-85d10ffba68f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def limpar_tweet(tweet):\n",
        "  tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "  tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "  tweet = re.sub(r'#', '', tweet)\n",
        "  return tweet\n",
        "\n",
        "#Guardaremos essa fun√ß√£o pois quando for preciso fazer usa-l√° para todo conjunto de dados chamaremos ela novamente"
      ],
      "metadata": {
        "id": "fw22I1mpRyXw"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_processamento(tweet):\n",
        "  tweet = limpar_tweet(tweet)\n",
        "  tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "\n",
        "  tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "  stopwords_english = stopwords.words('english')\n",
        "\n",
        "  tweet_clean = []\n",
        "  for word in tweet_tokens:\n",
        "    if (word not in stopwords_english and #remove stopwords\n",
        "        word not in string.punctuation): #remove pontua√ß√£o\n",
        "      tweet_clean.append(word)\n",
        "  return tweet_clean\n",
        "\n"
      ],
      "metadata": {
        "id": "azUZWaMcSw0T"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tweet)\n",
        "print(pre_processamento(tweet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzo2eTZ6T7PX",
        "outputId": "6e8441c0-504d-489e-9b5f-5ad604983c81"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off‚Ä¶ https://t.co/3tfYom0N1i\n",
            "['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', '‚Ä¶']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def steamming(tweet_clean):\n",
        "  stemmer = PorterStemmer()\n",
        "\n",
        "  tweets_stem = []\n",
        "  for word in tweet_clean:\n",
        "    stem_word = stemmer.stem(word) # stemming palavra\n",
        "    tweets_stem.append(stem_word)\n",
        "  return tweets_stem\n",
        "\n"
      ],
      "metadata": {
        "id": "Ipwl-grTUiW0"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tweet)\n",
        "print(pre_processamento(tweet))\n",
        "print(steamming(pre_processamento(tweet)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9mrSZZ-U_L8",
        "outputId": "cc647347-3310-4ffc-bce4-bfaf5acc7dba"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off‚Ä¶ https://t.co/3tfYom0N1i\n",
            "['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', '‚Ä¶']\n",
            "['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', '‚Ä¶']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_processamento_final(tweet):\n",
        "  return steamming(pre_processamento(tweet))"
      ],
      "metadata": {
        "id": "0TbjkRBiVfmu"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Parte 3 - An√°lise de frequ√™ncia"
      ],
      "metadata": {
        "id": "lOdS0WlTXGFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def construcao_freqs(tweets, ys):\n",
        "    \"\"\"Construcao de frequencias.\n",
        "    Input:\n",
        "        tweets: uma lista de tweets\n",
        "        ys: um array de m x 1 com a rotulagem de cada tweet (0,1)\n",
        "    Output:\n",
        "        freqs: um dicion√°rio mapeando (palavra,rotulo) para a frequencia\n",
        "    \"\"\"\n",
        "    # Converte o array np em lista, pois o zip precisa de um iter√°vel.\n",
        "    # o \"squeeze\" √© necess√°rio ou a lista acaba com um elemento.\n",
        "    yslist = np.squeeze(ys).tolist()\n",
        "\n",
        "    # Come√ßa com dicion√°rio vazio e vai populando conforme vai iterando\n",
        "    freqs = {}\n",
        "    for y, tweet in zip(yslist, tweets):\n",
        "        for word in pre_processamento_final(tweet):\n",
        "            pair = (word, y)\n",
        "            if pair in freqs:\n",
        "                freqs[pair] += 1\n",
        "            else:\n",
        "                freqs[pair] = 1\n",
        "\n",
        "    return freqs"
      ],
      "metadata": {
        "id": "TwmWwN3AXNC3"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Parte 4 - Regress√£o log√≠stica"
      ],
      "metadata": {
        "id": "hYXCQnyzaOz1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usando regress√£o log√≠stica para classifica√ß√£o de texto.\n",
        "\n",
        "A fun√ß√£o sigmoide √© definida como:\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAOMAAABYCAIAAACI4detAAAINUlEQVR4Ae2dwbWkKhCGSYEYTMEcDMEYTMEMXPfGDDoCIzABE3Dx9qQwwzvv1px6jCCCQrd0/72YY3OhgJ9PoErsERofKFCCAqKERqKNUECLBz5QoAQFxD8/n8fj8fv3b9y5UOC2CvxP6m2biIZBAa01SAUGZSgAUssYJ7QSpIKBMhQAqWWMU6pWKqW6rhOivOgkSE3FQAF2hmGQUoqfTwHN/buJIPVvPT702zRNVVURoyD1Qwe58G7N89w0jZSy7/t5npnX4rqFObW4IYtr8DzPbduu60rFmqbBnBqnIHK/RQGQ+hbZUWm0AiA1WjIUeIsCIPUtsqPSaAVAarRkKPAWBUDqW2RHpdEKgNRoyVDgLQqA1LfIjkqjFSiYVH4xIbrTKFCgAgWTqrX+9evX4/EoUHY0OVqBsknVWoPU6DEvswBILXPcvq/VIPX7xrzMHtd1TSdUlFJl9eDP2W+s/mUNW2xrl2WhQ1V8RLVt22malmWJNfWu/CD1Xcq/rl5e8RnTzcXrmnKhJpB6QTwUfaEC2UmlRadt26hOLctSVdUwDMVtp6K6iczhCmQkVSlF607TNNM0hbdJa72uK72eJqV8Pp9RZZH5IxUIIlUpNY6jud2RUjZNMwzD3pZ8WRb587nCGbPedd1Hqo9OhStwTCozNwwDvY6jlBqGgXblwzDYla3rSm/r7nFsF/GktG0rhOj73pMHf/p4BQ5IJUyFEPM8b7SgyJydrrWmP43juCly7qtSit6ojN1CnKsOpe6pwAGpNJ85/aG+750/xfF8PoUQVVUl7HAOmwmbB1MvUOCAVM8Sv9c4mv+ubE+dljOZddaFxBsqEERquEMzTRPBnTy6RFN4Xdc3FBFNeoECB6SSYySl5J828LeJfp2raRpPNtpRbB6TmF+dZed5pjyBLXEaQWK5ChyQSuTRvjPEkac12u+nU56u68x51x9M0ForpYjU8H2FSX/4dblj+dktPyBVKcWnb6SUfneeYfJkW9dVCLFx0chhEkL4txk0wftvA3O0wuk0c5oWcH0fBQ5IpcnMjPlv5kKzJ7xAO0NXlJM2suYKzlvbwz0oP/EyK8X1lyhwTCoJMY4jTzx729AQUjeycry2rmtzM7DJRl9vSyorg4vkCjAJoaRqrZkqIYTz0VQsqUop9thCNsEgNTkH9zd4hlStNbPoXKn5r57Vnys2d8AhmGqtb0sqdwoX+RSImFOpEexg2W2KIpVjVeG+fCyp5yYMu19IuYMC0aRyOMlufTipHPzyRAls+yDV1uR7UtykNj8fpwoEmXP1D4lSaa0DY1J27bFRKtsCUspVwE2q54gJxe2dHpXW+hAmjkltAgiEr0fHwNvAYwF/Oq3Asixt24ZHsqMqatu26zozcOks7iB1WRba4dmOEcWqPBElz4xrRg82FigI4JynudGM+GGXuAgukihAL1+EuxMnKh3H8fDlDgepvDpLKflI6LIstEPdQLZplocnjklVVWWGTtd1JS/Nf8v674FNM/A1lQJ930spA4MzVyqlGKjnfnCQSu8wtW1LHgzNr1LKtm09hriVtD2wXSV2xfZccr9x2lf483AbcJFEAXKRX6Y5rdh7d4WD1IudpPoynaQ2J+OL7UTxQwWapkk7joc1VlW1cWC4SHpS+e2UPa+L6w684G0Db0UCC749G/3Peql0eHF3yF2x18YTzeDY+WY5tW8DOoXsnFazkMrPXW2f7EQ/aRPiP2Z1wmzWIsuy8N6pUFIJmiQjWFVVXdfsCnvwoP2GU7EspLKbf+jQ+XEp8S1q/s+eef5w6u7vuP1XGsK9ldHOfz2F7rTrduicJ0+TvEI6t78Ui3R2Mxep9OsS1NumaWJvTfOXKZIsQNcVP7RAL5fTLyE8n0/2IAslVQghpTzsdVQGPuzhifPsxfIzkkp9+Kpf+zHDI/xsuVxSnXMb94sXDeeFc26icKR/I0fW7BsgO6l2lV+SwiMKUmnEKSLupN9EAqSaarzi+rakbn67iSLl7O6wNEKIQ6o48+EFv1p8GGcEqYdiJs5wT1LneZZSVlVFDg1vHG0o94g5IRM99ZRSHmKqtX7bPvVExz6jyA1JJWI2z8PZ89vInsr3Jx02j2TrunY6yu/x/Tc9/7avdyOVo5gcMKIRoXV5LwjvdIzCh5IrNe3QvWGmsEE6N+Lc2cOjYpUSX5wjlUvR4hv4r712252hOXLjdzNJdnSTWuIJJ9lV2Cn8hojdETuz1vrVz6icjfi2RGbOOUPsqcGl7KH1pBySyic5yXNalmWaJnLGPU9nqp/PXlNzpFM02mkZc6pTlgSJzFwUqXsVk7VDIveK01zFrNNBkL7v/UcpqFLnhnKvoivpnl3Bf54Wmcb/8nNFYmfZW5HqXPqdzd4kvvJ8qhDCc1eA1M3QJPt6K1JpNj03u9OZfw9D1yWjk6L+KkDqdZ3dFj6GVPqdhzu+R+UWHqmRCtyKVHoRw35TTSllnlWI7OJLs2NOzSU3v1J2MdBD7SPuT3tU5OabG0HztNomwppLkWt2Qeo1/azSSql5np/PJ734RWfnxnGc5znkWaJl70/CRVL5VCi7/3RhHnDeq/om6SA15UDwir8Bgr+e82n4F8FOz6l0XLjrOr5/mqaxo/0ptUhtC6SmVhT28igAUvPoCqupFQCpqRWFvTwKgNQ8usJqagVAampFYS+PAiA1j66wmloBkJpaUdjLowBIzaMrrKZWAKSmVhT28igAUvPoCqupFQCpqRWFvTwKgNQ8usJqagVAampFYS+PAiA1j66wmloBkJpaUdjLowBIzaMrrKZW4F+t8e6uWsnVUgAAAABJRU5ErkJggg==)\n",
        "\n",
        "\n",
        "Ela mapeia a entrada (z) para um valor entre 0 e 1, podendo assim ser interpretada como uma probabilidade.\n",
        "\n",
        "Implementa√ß√£o da fun√ß√£o sigmoide:\n",
        "\n",
        "- Voc√™ deve garantir que essa fun√ß√£o funcione corretamente tanto se z for um valor escalar (ex: um n√∫mero como 3.5) quanto se for um array (ex: uma lista ou vetor de valores).\n",
        "\n"
      ],
      "metadata": {
        "id": "_3uEy82caRnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoide(z):\n",
        "    '''\n",
        "    Entrada:\n",
        "        z: valor de entrada (pode ser um escalar ou um array)\n",
        "    Sa√≠da:\n",
        "        h: o resultado da fun√ß√£o sigmoide aplicada a z\n",
        "    '''\n",
        "\n",
        "    # calcula a fun√ß√£o sigmoide de z\n",
        "    h = 1 / (1 + np.exp(-z))\n",
        "\n",
        "    return h\n"
      ],
      "metadata": {
        "id": "xUYSIrU2a6V3"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testando a fun√ß√£o\n",
        "if (sigmoide(0) == 0.5):\n",
        "    print('SUCESSO!')\n",
        "else:\n",
        "    print('Oops!')\n",
        "\n",
        "if (sigmoide(4.92) == 0.9927537604041685):\n",
        "    print('CORRETO!')\n",
        "else:\n",
        "    print('Oops denovo!')\n",
        "\n",
        "print(sigmoide(np.array([0, 4.92])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD-IO6-abkEl",
        "outputId": "c10aff5f-7dd2-4423-df39-555d13dd756d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCESSO!\n",
            "CORRETO!\n",
            "[0.5        0.99275376]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regress√£o Log√≠stica: regress√£o + fun√ß√£o sigmoide\n",
        "\n",
        "A **regress√£o log√≠stica** come√ßa com uma **regress√£o linear comum** e, em seguida, aplica uma **fun√ß√£o sigmoide** ao resultado dessa regress√£o.\n",
        "\n",
        "#### Regress√£o Linear:\n",
        "\n",
        "$$\n",
        "z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_N x_N\n",
        "$$\n",
        "\n",
        "Observe que os valores de \\$\\theta\\$ s√£o os **pesos**.\n",
        "Usaremos a nota√ß√£o \\$\\theta\\$ para representar esses pesos.\n",
        "\n",
        "#### Regress√£o Log√≠stica:\n",
        "\n",
        "$$\n",
        "h(z) = \\frac{1}{1+\\exp^{-z}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_N x_N\n",
        "$$\n",
        "\n",
        "Chamaremos o valor `z` de **logits**.\n",
        "\n",
        "---\n",
        "\n",
        "Se quiser que eu converta isso diretamente em uma c√©lula Markdown pronta para o Colab, posso te passar tamb√©m.\n"
      ],
      "metadata": {
        "id": "NYpgbdbHdKyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 4.2  ‚Äì Fun√ß√£o de Custo e Gradiente\n",
        "\n",
        "A **fun√ß√£o de custo** usada na regress√£o log√≠stica √© a **m√©dia da perda logar√≠tmica (log loss)** em todos os exemplos de treinamento:\n",
        "\n",
        "$$\n",
        "J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m \\left[ y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1 - y^{(i)})\\log (1 - h(z(\\theta)^{(i)})) \\right] \\tag{5}\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "\n",
        "* $m$ √© o n√∫mero de exemplos de treinamento\n",
        "* $y^{(i)}$ √© o **r√≥tulo real** do exemplo de n√∫mero *i*\n",
        "* $h(z(\\theta)^{(i)})$ √© a **previs√£o do modelo** para o exemplo *i*\n",
        "\n",
        "---\n",
        "\n",
        "#### Fun√ß√£o de perda para um √∫nico exemplo:\n",
        "\n",
        "$$\n",
        "Loss = -1 \\times \\left[ y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1 - y^{(i)})\\log (1 - h(z(\\theta)^{(i)})) \\right]\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "#### Observa√ß√µes importantes:\n",
        "\n",
        "* Todos os valores de $h$ est√£o entre 0 e 1, ent√£o os logaritmos ser√£o **negativos**. Por isso, usamos o fator **-1** para tornar a soma positiva.\n",
        "* Quando o modelo prev√™ 1 ($h(z(\\theta)) = 1$) e o r√≥tulo $y$ tamb√©m √© 1, a perda √© **zero**.\n",
        "* O mesmo acontece se o modelo prev√™ 0 e o r√≥tulo real tamb√©m for 0: a perda ser√° **zero**.\n",
        "* No entanto, se o modelo prev√™ algo muito pr√≥ximo de 1 ($h(z(\\theta)) = 0.9999$) e o r√≥tulo real √© 0, o segundo termo da perda se torna um n√∫mero muito **negativo**, e multiplicando por -1 resulta em uma **perda positiva alta**.\n",
        "\n",
        "Exemplo:\n",
        "\n",
        "$$\n",
        "-1 \\times (1 - 0) \\times \\log(1 - 0.9999) \\approx 9.2\n",
        "$$\n",
        "\n",
        "üëâ Quanto mais pr√≥ximo de 1 for a previs√£o incorreta, **maior ser√° a penalidade**."
      ],
      "metadata": {
        "id": "OKhI0YL0dezY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# verifique que, quando o modelo prev√™ um valor pr√≥ximo de 1, mas o r√≥tulo real √© 0, a perda √© um valor positivo alto\n",
        "-1 * (1 - 0) * np.log(1 - 0.9999)  # perda √© aproximadamente 9.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWuz_8dhdKHo",
        "outputId": "29a89349-9f58-43e6-900d-66f765f5a339"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(9.210340371976294)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Atualiza√ß√£o dos Pesos\n",
        "\n",
        "Para atualizar o vetor de pesos $\\theta$, aplicarei o **Gradiente Descendente** para melhorar iterativamente as previs√µes do modelo.\n",
        "\n",
        "O gradiente da fun√ß√£o de custo $J$ em rela√ß√£o a um dos pesos $\\theta_j$ √© dado por:\n",
        "\n",
        "$$\n",
        "\\nabla_{\\theta_j}J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m(h^{(i)} - y^{(i)})x_j \\tag{5}\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "\n",
        "* $i$ √© o √≠ndice de cada um dos $m$ exemplos de treinamento\n",
        "* $j$ √© o √≠ndice do peso $\\theta_j$, e $x_j$ √© a caracter√≠stica (feature) associada a esse peso\n",
        "\n",
        "---\n",
        "\n",
        "Para atualizar o peso $\\theta_j$, ajustamos seu valor **subtraindo uma fra√ß√£o do gradiente**, determinada pela taxa de aprendizado $\\alpha$:\n",
        "\n",
        "$$\n",
        "\\theta_j = \\theta_j - \\alpha \\times \\nabla_{\\theta_j}J(\\theta)\n",
        "$$\n",
        "\n",
        "* A **taxa de aprendizado** $\\alpha$ √© um valor escolhido manualmente e **controla o tamanho de cada atualiza√ß√£o** dos pesos."
      ],
      "metadata": {
        "id": "Rw8d87BoeU4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradientDescent(x, y, theta, alpha, num_iters):\n",
        "    '''\n",
        "    Entrada:\n",
        "        x: matriz de caracter√≠sticas (features), com dimens√µes (m, n+1)\n",
        "        y: r√≥tulos correspondentes √† matriz de entrada x, dimens√µes (m, 1)\n",
        "        theta: vetor de pesos com dimens√£o (n+1, 1)\n",
        "        alpha: taxa de aprendizado\n",
        "        num_iters: n√∫mero de itera√ß√µes que voc√™ deseja treinar seu modelo\n",
        "    Sa√≠da:\n",
        "        J: custo final\n",
        "        theta: vetor de pesos final\n",
        "    Dica: voc√™ pode querer imprimir o custo para garantir que ele est√° diminuindo.\n",
        "    '''\n",
        "    ### IN√çCIO DO C√ìDIGO ###\n",
        "    # obt√©m 'm', o n√∫mero de linhas da matriz x\n",
        "    m = x.shape[0]\n",
        "\n",
        "    for i in range(0, num_iters):\n",
        "\n",
        "        # calcula z, o produto escalar de x e theta\n",
        "        z = np.dot(x, theta)\n",
        "\n",
        "        # calcula h, a fun√ß√£o sigmoide aplicada a z\n",
        "        h = sigmoide(z)\n",
        "\n",
        "        # calcula a fun√ß√£o de custo\n",
        "        # note que tamb√©m poder√≠amos usar np.array.transpose() ao inv√©s de np.array.T\n",
        "        # np.array.T apenas deixa o c√≥digo mais leg√≠vel :)\n",
        "        J = -1./m * (np.dot(y.T, np.log(h)) + np.dot((1 - y).T, np.log(1 - h)))\n",
        "\n",
        "        # atualiza os pesos theta\n",
        "        theta = theta - (alpha/m) * np.dot(x.T, (h - y))\n",
        "\n",
        "    ### FIM DO C√ìDIGO ###\n",
        "    J = float(J)\n",
        "    return J, theta\n"
      ],
      "metadata": {
        "id": "trQRnukLfnxc"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica a fun√ß√£o\n",
        "# Constr√≥i um caso de teste sint√©tico usando fun√ß√µes de gera√ß√£o de n√∫meros aleat√≥rios do numpy\n",
        "np.random.seed(1)  # Define a semente para reprodu√ß√£o dos resultados\n",
        "\n",
        "# A entrada X √© uma matriz 10 x 3 com uns na primeira coluna para o termo de bias\n",
        "tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n",
        "\n",
        "# Os r√≥tulos Y s√£o uma matriz 10 x 1\n",
        "tmp_Y = (np.random.rand(10, 1) > 0.35).astype(float)\n",
        "\n",
        "# Aplica o gradiente descendente\n",
        "tmp_J, tmp_theta = gradientDescent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 700)\n",
        "\n",
        "# Imprime o custo ap√≥s o treinamento\n",
        "print(f\"O custo ap√≥s o treinamento √© {tmp_J:.8f}.\")\n",
        "\n",
        "# Imprime o vetor de pesos resultante\n",
        "print(f\"O vetor resultante de pesos √© {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzTmCJ-Lg4-H",
        "outputId": "6893aaac-5386-4dcc-988c-6fcacb704d72"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O custo ap√≥s o treinamento √© 0.67094970.\n",
            "O vetor resultante de pesos √© [np.float64(4.1e-07), np.float64(0.00035658), np.float64(7.309e-05)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-dde2da729d09>:35: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  J = float(J)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(tweet, freqs):\n",
        "    '''\n",
        "    Entrada:\n",
        "        tweet: uma lista de palavras (tokens) de um tweet\n",
        "        freqs: um dicion√°rio com a contagem de vezes que (palavra, label) aparece.\n",
        "\n",
        "    Sa√≠da:\n",
        "        x: um vetor de caracter√≠sticas com dimens√£o (1,3)\n",
        "           [1, contagem_palavras_positivas, contagem_palavras_negativas]\n",
        "    '''\n",
        "\n",
        "    # processa o tweet (remove stopwords, faz stemming, etc.)\n",
        "    word_l = pre_processamento_final(tweet)\n",
        "\n",
        "    # cria um vetor de caracter√≠sticas com 3 posi√ß√µes\n",
        "    x = np.zeros((1, 3))\n",
        "\n",
        "    # o primeiro valor √© sempre 1 (termo de vi√©s/bias)\n",
        "    x[0,0] = 1\n",
        "\n",
        "    # percorre todas as palavras processadas do tweet\n",
        "    for word in word_l:\n",
        "\n",
        "        # se a palavra aparecer com o r√≥tulo positivo (1.0) no dicion√°rio, soma a frequ√™ncia\n",
        "        if (word, 1.0) in freqs:\n",
        "            x[0,1] += freqs[(word, 1.0)]\n",
        "\n",
        "        # se a palavra aparecer com o r√≥tulo negativo (0.0), soma a frequ√™ncia tamb√©m\n",
        "        if (word, 0.0) in freqs:\n",
        "            x[0,2] += freqs[(word, 0.0)]\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "EzHUL5BxkeZZ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 5 - Treinamento do modelo"
      ],
      "metadata": {
        "id": "qlkRnYrXevfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#separando em teste e treino do modelo\n",
        "test_pos = all_positive_tweets[4000:]\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg"
      ],
      "metadata": {
        "id": "iGytyY6t1vU_"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combina rotulos positivos e negativos\n",
        "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
        "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)\n"
      ],
      "metadata": {
        "id": "B8J0JHGV18Cg"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime o shape\n",
        "print(\"train_y.shape = \" + str(train_y.shape))\n",
        "print(\"test_y.shape = \" + str(test_y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XX9cKAW3Air",
        "outputId": "8c353389-2ae5-4120-dac2-cde21f8b3a9d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_y.shape = (8000, 1)\n",
            "test_y.shape = (2000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = construcao_freqs(train_x, train_y)\n",
        "\n",
        "print('type(freqs) = '+str(type(freqs)))\n",
        "print('len(freqs)= '+str(len(freqs.keys())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKis5LAb3maz",
        "outputId": "5445e3f6-2926-4311-dbfd-d2ce8128f98f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(freqs) = <class 'dict'>\n",
            "len(freqs)= 11306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the function below\n",
        "print('Exemplo de um tweet positivo: \\n', train_x[0])\n",
        "print('\\nExemplo de um tweet ap√≥s ser processado: \\n', pre_processamento_final(train_x[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsedLQ9D4OOR",
        "outputId": "f2b417e7-9e32-4e42-b368-f13ae759843e"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemplo de um tweet positivo: \n",
            " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
            "\n",
            "Exemplo de um tweet ap√≥s ser processado: \n",
            " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(train_x),3))\n",
        "for i in range(len(train_x)):\n",
        "  X[i, :] = extract_features(train_x[i], freqs)\n",
        "\n",
        "Y = train_y\n",
        "\n",
        "J , theta = gradientDescent(X, Y, np.zeros((3,1)), 1e-9, 1500)\n",
        "\n",
        "print(f\"O custo ap√≥s o treinamento √© {J:.8f}.\")\n",
        "print(f\"O vetor resultante de pesos √© {[round(t, 8) for t in np.squeeze(theta)]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZlUf1i-4l-0",
        "outputId": "63c231ca-b608-40ed-9e74-5798b3b4dc52"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O custo ap√≥s o treinamento √© 0.24217224.\n",
            "O vetor resultante de pesos √© [np.float64(7e-08), np.float64(0.00052352), np.float64(-0.00055579)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-dde2da729d09>:35: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  J = float(J)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 6 - Testando modelo"
      ],
      "metadata": {
        "id": "MKnp9wVF5a41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C4 (IDENTIFICADOR √öNICO DA C√âLULA, N√ÉO EDITAR)\n",
        "def predicao_tweet(tweet, freqs, theta):\n",
        "    '''\n",
        "    Entrada:\n",
        "        tweet: uma string (o texto do tweet)\n",
        "        freqs: um dicion√°rio com a frequ√™ncia de cada tupla (palavra, r√≥tulo)\n",
        "        theta: vetor de pesos de dimens√£o (3,1)\n",
        "\n",
        "    Sa√≠da:\n",
        "        y_pred: a probabilidade do tweet ser positivo (ou negativo)\n",
        "    '''\n",
        "    ### IN√çCIO DO C√ìDIGO ###\n",
        "\n",
        "    # extrai as caracter√≠sticas do tweet e armazena em x\n",
        "    x = extract_features(tweet, freqs)\n",
        "\n",
        "    # faz a previs√£o usando x e theta (produto escalar e fun√ß√£o sigmoide)\n",
        "    y_pred = sigmoide(np.dot(x, theta))\n",
        "\n",
        "    ### FIM DO C√ìDIGO ###\n",
        "\n",
        "    return y_pred\n"
      ],
      "metadata": {
        "id": "Tbrrpr__5aIu"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo para testar a predicao\n",
        "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
        "    print( '%s -> %f' % (tweet, predicao_tweet(tweet, freqs, theta)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCDypymm59zD",
        "outputId": "cc18ccf3-a587-4145-efb2-53ec36a79d28"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am happy -> 0.518562\n",
            "I am bad -> 0.494329\n",
            "this movie should have been great. -> 0.515312\n",
            "great -> 0.515449\n",
            "great great -> 0.530868\n",
            "great great great -> 0.546228\n",
            "great great great great -> 0.561501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-5ac626e7c0f5>:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print( '%s -> %f' % (tweet, predicao_tweet(tweet, freqs, theta)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meu_tweet = 'I am learning :)'\n",
        "predicao_tweet(meu_tweet, freqs, theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggyy0S7b6I-c",
        "outputId": "3c929579-02a5-46ef-95dc-c495acbdec94"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8162007]])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##  Parte 7 - Verificar o desempenho usando o conjunto de teste\n",
        "\n",
        "Depois de treinar o seu modelo com o conjunto de treinamento, √© hora de verificar **como ele se comporta com dados reais e in√©ditos**, testando-o com o conjunto de teste.\n",
        "\n",
        "---\n",
        "\n",
        "###  Instru√ß√µes: Implemente a fun√ß√£o `test_logistic_regression`\n",
        "\n",
        "O objetivo √© **calcular a acur√°cia** (percentual de acertos) do seu modelo de regress√£o log√≠stica usando os dados de teste e os pesos `theta` que voc√™ treinou.\n",
        "\n",
        "---\n",
        "\n",
        "###  Etapas para implementar:\n",
        "\n",
        "1. Para cada tweet do conjunto de teste, use a fun√ß√£o `predict_tweet()` para fazer a **previs√£o de probabilidade**.\n",
        "\n",
        "2. Se a **probabilidade prevista for maior que 0.5**, voc√™ considera que o modelo classificou o tweet como **positivo** (ou seja, `y_hat = 1`).\n",
        "   Caso contr√°rio, a classifica√ß√£o √© **negativa** (`y_hat = 0`).\n",
        "\n",
        "3. Compare a previs√£o `y_hat` com o valor real do r√≥tulo (`test_y`).\n",
        "\n",
        "4. Conte **quantas vezes a previs√£o foi correta**, ou seja, `y_hat == test_y`.\n",
        "\n",
        "5. Calcule a acur√°cia:\n",
        "\n",
        "   $$\n",
        "   \\text{acur√°cia} = \\frac{\\text{n√∫mero de acertos}}{m}\n",
        "   $$\n",
        "\n",
        "   onde `m` √© o n√∫mero total de exemplos no conjunto de teste.\n"
      ],
      "metadata": {
        "id": "GDGJ_9IA6k3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def testar_regressao_logistica(test_x, test_y, freqs, theta):\n",
        "    \"\"\"\n",
        "    Entrada:\n",
        "        test_x: uma lista de tweets\n",
        "        test_y: vetor (m, 1) com os r√≥tulos reais correspondentes a cada tweet\n",
        "        freqs: um dicion√°rio com a frequ√™ncia de cada par (palavra, r√≥tulo)\n",
        "        theta: vetor de pesos com dimens√£o (3, 1)\n",
        "    Sa√≠da:\n",
        "        acuracia: (n√∫mero de tweets classificados corretamente) / (n√∫mero total de tweets)\n",
        "    \"\"\"\n",
        "\n",
        "    # lista para armazenar as previs√µes\n",
        "    y_hat = []\n",
        "\n",
        "    for tweet in test_x:\n",
        "        # obter a previs√£o do r√≥tulo para o tweet\n",
        "        y_pred = predicao_tweet(tweet, freqs, theta)\n",
        "\n",
        "        if y_pred > 0.5:\n",
        "            # adicionar 1.0 √† lista se for positivo\n",
        "            y_hat.append(1)\n",
        "        else:\n",
        "            # adicionar 0 se for negativo\n",
        "            y_hat.append(0)\n",
        "\n",
        "    # y_hat √© uma lista e test_y √© um array (m,1)\n",
        "    # converter ambos para arrays unidimensionais para comparar com o operador '=='\n",
        "    acuracia = (y_hat == np.squeeze(test_y)).sum() / len(test_x)\n",
        "\n",
        "    return acuracia\n"
      ],
      "metadata": {
        "id": "sf5x8t-86n75"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_accuracy = testar_regressao_logistica(test_x, test_y, freqs, theta)\n",
        "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5hCpDPp7Nc4",
        "outputId": "9c2ff066-3e37-4a8d-dfdd-b762a9c066e6"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression model's accuracy = 0.9965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Parte 8 - Teste seu pr√≥prio tweet"
      ],
      "metadata": {
        "id": "fKD_O7Q77Ze4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pode se sentir livre para mudar o tweet abaixo\n",
        "my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\n",
        "print(pre_processamento_final(my_tweet))\n",
        "y_hat = predicao_tweet(my_tweet, freqs, theta)\n",
        "print(y_hat)\n",
        "if y_hat > 0.5:\n",
        "    print('Positive sentiment')\n",
        "else:\n",
        "    print('Negative sentiment')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQiXwX8U7hsy",
        "outputId": "015ef35f-def7-425e-c6b8-31bd47f84360"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ridicul', 'bright', 'movi', 'plot', 'terribl', 'sad', 'end']\n",
            "[[0.48136088]]\n",
            "Negative sentiment\n"
          ]
        }
      ]
    }
  ]
}