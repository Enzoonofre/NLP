{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TAq7d4FXAc2b"
      },
      "outputs": [],
      "source": [
        "from utils import process_tweet, lookup\n",
        "import pdb\n",
        "from nltk.corpus import stopwords, twitter_samples\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from os import getcwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('twitter_samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_lW_j9oBhE6",
        "outputId": "12276b2c-bd2a-45d3-9469-8055da2a1b04"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pegando todos os tweets positivos e negativos\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "# divide os dados em teste e treino\n",
        "test_pos = all_positive_tweets[4000:]\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg\n",
        "\n",
        "# cria o rótulo dos dados, 1 para positivo e 0 para negativo\n",
        "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
        "test_y = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))"
      ],
      "metadata": {
        "id": "x5bMpBFnBjqU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 1: Processar os Dados\n",
        "\n",
        "Para qualquer projeto de aprendizado de máquina, uma vez que você tenha reunido os dados, o primeiro passo é processá-los para gerar entradas úteis para o seu modelo.\n",
        "\n",
        "* **Remover ruído**: Primeiro, você vai querer remover o \"ruído\" dos seus dados — ou seja, eliminar palavras que não dizem muito sobre o conteúdo. Isso inclui todas as palavras comuns como “eu, você, é, está, etc.”, que não nos dão informação suficiente sobre o sentimento.\n",
        "* Também vamos remover códigos de ações da bolsa de valores, símbolos de retweet, hyperlinks e hashtags, porque eles não fornecem muita informação sobre o sentimento.\n",
        "* Você também deve remover toda a pontuação de um tweet. A razão para isso é que queremos tratar palavras com ou sem pontuação como a mesma palavra, ao invés de considerar \"feliz\", \"feliz?\", \"feliz!\", \"feliz,\" e \"feliz.\" como palavras diferentes.\n",
        "* Por fim, você deve usar o *stemming* para manter apenas uma variação de cada palavra. Em outras palavras, vamos tratar \"motivação\", \"motivado\" e \"motivar\" de forma semelhante, agrupando todas na mesma raiz “motiv-”.\n",
        "\n",
        "Usaremos a função `process_tweet()` que faz esse processamento\n"
      ],
      "metadata": {
        "id": "OU6WG82OB1sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "def process_tweet(tweet):\n",
        "    '''\n",
        "    Entrada:\n",
        "        tweet: uma string contendo um tweet\n",
        "    Saída:\n",
        "        tweets_clean: uma lista de palavras contendo o tweet processado\n",
        "    '''\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "\n",
        "    # remove tickers da bolsa como $GE\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    # remove textos de retweet do estilo antigo \"RT\"\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    # remove hyperlinks\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    # remove hashtags\n",
        "    # apenas remove o símbolo # da palavra\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "\n",
        "    # tokeniza os tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                                reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and  # remove palavras irrelevantes (stopwords)\n",
        "            word not in string.punctuation):   # remove pontuação\n",
        "            stem_word = stemmer.stem(word)     # aplica stemming à palavra\n",
        "            tweets_clean.append(stem_word)\n",
        "\n",
        "    return tweets_clean\n",
        "\n"
      ],
      "metadata": {
        "id": "131LMqBECla_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_tweet = \"RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning http://chapagain.com.np\"\n",
        "\n",
        "# imprimindo tweet processado\n",
        "print(process_tweet(custom_tweet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVWAcS_nFVrH",
        "outputId": "e6182ec4-54aa-40ed-c9f4-0e7abcb1ba3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'great', 'day', ':)', 'good', 'morn']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 1.1 Implementando suas funções auxiliares\n",
        "\n",
        "Para ajudar no treinamento do seu modelo de Naive Bayes, você precisará construir um **dicionário** onde as chaves são tuplas (palavra, rótulo) e os valores são as **frequências correspondentes**.\n",
        "Note que os rótulos que usaremos aqui são **1 para positivo** e **0 para negativo**.\n",
        "\n",
        "Você também implementará uma função auxiliar chamada `lookup()` que recebe como entrada o dicionário `freqs`, uma palavra e um rótulo (1 ou 0), e retorna o número de vezes que essa tupla (palavra, rótulo) aparece na coleção de tweets.\n",
        "\n",
        "Por exemplo: dado uma lista de tweets `[\"i am rather excited\", \"you are rather happy\"]` e o rótulo 1, a função retornará um dicionário contendo os seguintes pares chave-valor:\n",
        "\n",
        "```python\n",
        "{\n",
        "    (\"rather\", 1): 2,\n",
        "    (\"happi\", 1): 1,\n",
        "    (\"excit\", 1): 1\n",
        "}\n",
        "```\n",
        "\n",
        "* Observe que para cada palavra na string fornecida, o mesmo rótulo `1` é atribuído a cada palavra.\n",
        "* Observe que as palavras \"i\" e \"am\" não são salvas, pois foram removidas pela função `process_tweet()` por serem *stopwords*.\n",
        "* Observe que a palavra \"rather\" aparece duas vezes na lista de tweets, então seu valor de contagem é `2`.\n",
        "\n",
        "---\n",
        "\n",
        "###  Instruções\n",
        "\n",
        "Crie uma função `count_tweets()` que receba uma lista de tweets como entrada, limpe todos eles e retorne um dicionário.\n",
        "\n",
        "* A **chave** no dicionário deve ser uma tupla contendo a palavra com *stemming* aplicada e seu rótulo, por exemplo: `(\"happi\", 1)`.\n",
        "* O **valor** é o número de vezes que essa palavra aparece na coleção de tweets fornecida (um número inteiro).\n"
      ],
      "metadata": {
        "id": "i84Y02pHFynw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tweets(result, tweets, ys):\n",
        "    '''\n",
        "    Entrada:\n",
        "        result: um dicionário que será usado para mapear cada par (palavra, rótulo) para sua frequência\n",
        "        tweets: uma lista de tweets\n",
        "        ys: uma lista correspondente ao sentimento de cada tweet (0 ou 1)\n",
        "    Saída:\n",
        "        result: um dicionário mapeando cada par para sua frequência\n",
        "    '''\n",
        "\n",
        "    ### INÍCIO DO CÓDIGO ###\n",
        "    for y, tweet in zip(ys, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            # define a chave, que é a tupla (palavra, rótulo)\n",
        "            pair = (word, y)\n",
        "\n",
        "            # se a chave já existe no dicionário, incrementa o contador\n",
        "            if pair in result:\n",
        "                result[pair] += 1\n",
        "\n",
        "            # senão, se a chave for nova, adiciona ao dicionário com valor 1\n",
        "            else:\n",
        "                result[pair] = 1\n",
        "    ### FIM DO CÓDIGO ###\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "0x6Z4KadF2CJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Codigo acima já implementado no ultimo projeto de análise de sentimento usando regressão logística"
      ],
      "metadata": {
        "id": "h1RhdBdnG_kS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#testando função\n",
        "\n",
        "result = {}\n",
        "tweets = ['i am happy', 'i am tricked', 'i am sad', 'i am tired', 'i am tired']\n",
        "ys = [1, 0, 0, 0, 0]\n",
        "count_tweets(result, tweets, ys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZn6K8mtHfob",
        "outputId": "1ee55fd0-57d0-4468-96b4-d4f497adce67"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('happi', 1): 1, ('trick', 0): 1, ('sad', 0): 1, ('tire', 0): 2}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 2: Treine seu modelo usando Naive Bayes\n",
        "\n",
        "**Naive Bayes** é um algoritmo que pode ser utilizado para análise de sentimentos. Ele leva pouco tempo para ser treinado e também realiza previsões rapidamente.\n",
        "\n",
        "---\n",
        "\n",
        "#### Como treinar um classificador Naive Bayes?\n",
        "\n",
        "* A primeira parte do treinamento de um classificador Naive Bayes é identificar o número de **classes** que você possui.\n",
        "* Você criará uma **probabilidade para cada classe**.\n",
        "  $P(D_{pos})$ é a probabilidade de que o documento (tweet) seja **positivo**.\n",
        "  $P(D_{neg})$ é a probabilidade de que o documento (tweet) seja **negativo**.\n",
        "\n",
        "Use as seguintes fórmulas e armazene os valores em um dicionário:\n",
        "\n",
        "$$\n",
        "P(D_{pos}) = \\frac{D_{pos}}{D} \\tag{1}\n",
        "$$\n",
        "\n",
        "$$\n",
        "P(D_{neg}) = \\frac{D_{neg}}{D} \\tag{2}\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "\n",
        "* $D$ é o número total de documentos (neste caso, **tweets**),\n",
        "* $D_{pos}$ é o número total de **tweets positivos**,\n",
        "* $D_{neg}$ é o número total de **tweets negativos**.\n"
      ],
      "metadata": {
        "id": "pS5u_k7XJyUx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Prior e Logprior**\n",
        "\n",
        "A **probabilidade a priori** representa a probabilidade subjacente, na população-alvo, de que um tweet seja positivo em comparação com negativo.\n",
        "Em outras palavras, se não tivéssemos nenhuma informação específica e escolhêssemos um tweet aleatoriamente do conjunto da população, qual seria a chance de ele ser positivo ou negativo?\n",
        "Essa é a **probabilidade a priori** (ou simplesmente **prior**).\n",
        "\n",
        "O prior é a razão entre as probabilidades:\n",
        "\n",
        "$$\n",
        "\\frac{P(D_{pos})}{P(D_{neg})}\n",
        "$$\n",
        "\n",
        "Podemos tirar o logaritmo dessa razão para reescalá-la, e chamamos isso de **logprior**:\n",
        "\n",
        "$$\n",
        "\\text{logprior} = \\log \\left( \\frac{P(D_{pos})}{P(D_{neg})} \\right) = \\log \\left( \\frac{D_{pos}}{D_{neg}} \\right)\n",
        "$$\n",
        "\n",
        "Observe que:\n",
        "\n",
        "$$\n",
        "\\log\\left(\\frac{A}{B}\\right) = \\log(A) - \\log(B)\n",
        "$$\n",
        "\n",
        "Então o logprior também pode ser calculado como a diferença entre dois logaritmos:\n",
        "\n",
        "$$\n",
        "\\text{logprior} = \\log (P(D_{pos})) - \\log (P(D_{neg})) = \\log (D_{pos}) - \\log (D_{neg}) \\tag{3}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "uTSTBMPFKdgn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Probabilidade Positiva e Negativa de uma Palavra**\n",
        "\n",
        "Para calcular a **probabilidade positiva** e a **probabilidade negativa** de uma palavra específica no vocabulário, usaremos as seguintes entradas:\n",
        "\n",
        "* \\$freq\\_{pos}\\$ e \\$freq\\_{neg}\\$ são as **frequências** dessa palavra específica na classe positiva ou negativa.\n",
        "  Em outras palavras, a frequência positiva de uma palavra é o número de vezes que a palavra aparece com o rótulo 1.\n",
        "\n",
        "* \\$N\\_{pos}\\$ e \\$N\\_{neg}\\$ são o **número total de palavras positivas e negativas** em todos os documentos (ou seja, em todos os tweets), respectivamente.\n",
        "\n",
        "* \\$V\\$ é o **número de palavras únicas** em todo o conjunto de documentos, considerando todas as classes, tanto positivas quanto negativas.\n",
        "\n",
        "Usaremos esses valores para calcular a probabilidade positiva e negativa de uma palavra específica utilizando as fórmulas abaixo:\n",
        "\n",
        "$$\n",
        "P(W_{pos}) = \\frac{freq_{pos} + 1}{N_{pos} + V} \\tag{4}\n",
        "$$\n",
        "\n",
        "$$\n",
        "P(W_{neg}) = \\frac{freq_{neg} + 1}{N_{neg} + V} \\tag{5}\n",
        "$$\n",
        "\n",
        "Observe que adicionamos o \"+1\" no numerador para aplicar o **suavização laplaciana**\n"
      ],
      "metadata": {
        "id": "QbRIBa-KLQnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Criar o dicionário `freqs`\n",
        "\n",
        "* Usando a sua função `count_tweets()`, você pode calcular um dicionário chamado `freqs` que contém todas as frequências.\n",
        "* Nesse dicionário `freqs`, a chave é a tupla (palavra, rótulo)\n",
        "* O valor é o número de vezes que essa tupla apareceu.\n",
        "\n",
        "Usaremos esse dicionário em várias partes desta atividade.\n"
      ],
      "metadata": {
        "id": "-hI6P5chMAnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = count_tweets({}, train_x, train_y)"
      ],
      "metadata": {
        "id": "IunhZV3DKepu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instruções\n",
        "\n",
        "Dado um dicionário `freqs`, `train_x` (uma lista de tweets) e `train_y` (uma lista de rótulos para cada tweet), implemente um classificador Naive Bayes.\n",
        "\n",
        "##### Calcular \\$V\\$\n",
        "\n",
        "* Você pode calcular o número de palavras únicas que aparecem no dicionário `freqs` para obter seu \\$V\\$ (você pode usar a função `set`).\n",
        "\n",
        "##### Calcular \\$freq\\_{pos}\\$ e \\$freq\\_{neg}\\$\n",
        "\n",
        "* Usando seu dicionário `freqs`, você pode calcular a frequência positiva e negativa de cada palavra, \\$freq\\_{pos}\\$ e \\$freq\\_{neg}\\$.\n",
        "\n",
        "##### Calcular \\$N\\_{pos}\\$, \\$N\\_{neg}\\$, \\$V\\_{pos}\\$ e \\$V\\_{neg}\\$\n",
        "\n",
        "* Usando o dicionário `freqs`, você também pode calcular o número total de palavras positivas e o número total de palavras negativas, \\$N\\_{pos}\\$ e \\$N\\_{neg}\\$.\n",
        "* Da mesma forma, use o dicionário `freqs` para calcular o número total de palavras **únicas** positivas, \\$V\\_{pos}\\$, e o número total de palavras **únicas** negativas, \\$V\\_{neg}\\$.\n",
        "\n",
        "##### Calcular \\$D\\$, \\$D\\_{pos}\\$, \\$D\\_{neg}\\$\n",
        "\n",
        "* Usando a lista `train_y` de rótulos, calcule o número total de documentos (tweets), \\$D\\$, bem como o número de documentos positivos (tweets), \\$D\\_{pos}\\$, e o número de documentos negativos (tweets), \\$D\\_{neg}\\$.\n",
        "* Calcule a probabilidade de um documento (tweet) ser positivo \\$P(D\\_{pos})\\$ e a probabilidade de ser negativo \\$P(D\\_{neg})\\$.\n",
        "\n",
        "##### Calcular o logprior\n",
        "\n",
        "* O `logprior` é \\$log(D\\_{pos}) - log(D\\_{neg})\\$\n",
        "\n",
        "##### Calcular a verossimilhança logarítmica (log likelihood)\n",
        "\n",
        "* Por fim, você pode iterar sobre cada palavra do vocabulário, usar sua função `lookup` para obter as frequências positivas \\$freq\\_{pos}\\$ e negativas \\$freq\\_{neg}\\$ para aquela palavra específica.\n",
        "* Calcule a probabilidade positiva de cada palavra \\$P(W\\_{pos})\\$ e a probabilidade negativa \\$P(W\\_{neg})\\$ usando as equações (4) e (5):\n",
        "\n",
        "$P(W_{pos}) = \\frac{freq_{pos} + 1}{N_{pos} + V} \\tag{4}$\n",
        "$P(W_{neg}) = \\frac{freq_{neg} + 1}{N_{neg} + V} \\tag{5}$\n",
        "\n",
        "**Nota:** Vamos usar um dicionário para armazenar as verossimilhanças logarítmicas de cada palavra. A chave será a palavra, e o valor será a log likelihood dessa palavra.\n",
        "\n",
        "* Você pode então calcular a `loglikelihood`:\n",
        "  \\$log \\left( \\frac{P(W\\_{pos})}{P(W\\_{neg})} \\right)\\$.\n"
      ],
      "metadata": {
        "id": "A_m_SaVhEkUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def treinar_naive_bayes(freqs, train_x, train_y):\n",
        "    '''\n",
        "    Entrada:\n",
        "        freqs: dicionário de (palavra, rótulo) para a frequência com que a palavra aparece\n",
        "        train_x: uma lista de tweets\n",
        "        train_y: uma lista de rótulos correspondentes aos tweets (0,1)\n",
        "    Saída:\n",
        "        logprior: o log do prior. (equação 3 acima)\n",
        "        loglikelihood: a verossimilhança logarítmica da equação de Naive Bayes. (equação 6 acima)\n",
        "    '''\n",
        "    loglikelihood = {}\n",
        "    logprior = 0\n",
        "\n",
        "    # calcular V, o número de palavras únicas no vocabulário\n",
        "    vocab = set([par[0] for par in freqs.keys()])\n",
        "    V = len(vocab)\n",
        "\n",
        "    # calcular N_pos, N_neg, V_pos, V_neg\n",
        "    N_pos = N_neg = V_pos = V_neg = 0\n",
        "    for par in freqs.keys():\n",
        "        # se o rótulo for positivo (maior que zero)\n",
        "        if par[1] > 0:\n",
        "            # incrementa o número de palavras positivas únicas\n",
        "            V_pos += 1\n",
        "\n",
        "            # incrementa o número total de palavras positivas com a frequência do par (palavra, rótulo)\n",
        "            N_pos += freqs[par]\n",
        "\n",
        "        # senão, o rótulo é negativo\n",
        "        else:\n",
        "            # incrementa o número de palavras negativas únicas\n",
        "            V_neg += 1\n",
        "\n",
        "            # incrementa o número total de palavras negativas com a frequência do par (palavra, rótulo)\n",
        "            N_neg += freqs[par]\n",
        "\n",
        "    # calcular D, o número total de documentos\n",
        "    D = len(train_y)\n",
        "\n",
        "    # calcular D_pos, o número de documentos positivos\n",
        "    D_pos = len(list(filter(lambda x: x > 0, train_y)))\n",
        "\n",
        "    # calcular D_neg, o número de documentos negativos\n",
        "    D_neg = len(list(filter(lambda x: x <= 0, train_y)))\n",
        "\n",
        "    # calcular o logprior\n",
        "    logprior = np.log(D_pos) - np.log(D_neg)\n",
        "\n",
        "    # para cada palavra no vocabulário...\n",
        "    for palavra in vocab:\n",
        "        # obtém a frequência positiva e negativa da palavra\n",
        "        freq_pos = lookup(freqs, palavra, 1)\n",
        "        freq_neg = lookup(freqs, palavra, 0)\n",
        "\n",
        "        # calcula a probabilidade de a palavra ser positiva e negativa\n",
        "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
        "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
        "\n",
        "        # calcula a verossimilhança logarítmica da palavra\n",
        "        loglikelihood[palavra] = np.log(p_w_pos / p_w_neg)\n",
        "\n",
        "    ### FIM DO CÓDIGO ###\n",
        "\n",
        "    return logprior, loglikelihood\n"
      ],
      "metadata": {
        "id": "osw1hZtLEzMe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logprior, loglikelihood = treinar_naive_bayes(freqs, train_x, train_y)\n",
        "print(logprior)\n",
        "print(len(loglikelihood))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-t7hz3jFose",
        "outputId": "7dd40e5e-da70-4a1f-ad45-351bec5deb41"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "9067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 3: Teste seu Naive Bayes\n",
        "\n",
        "Agora que temos o `logprior` e o `loglikelihood`, podemos testar a função de Naive Bayes fazendo previsões em alguns tweets!\n",
        "\n",
        "#### Implemente `naive_bayes_predicao`\n",
        "\n",
        "**Instruções**:\n",
        "Implemente a função `naive_bayes_predicao` para fazer previsões em tweets.\n",
        "\n",
        "* A função recebe como entrada o `tweet`, o `logprior` e o `loglikelihood`.\n",
        "* Ela retorna a **probabilidade** de que o tweet pertença à classe positiva ou negativa.\n",
        "* Para cada tweet, some as verossimilhanças logarítmicas (`loglikelihood`) de cada palavra contida no tweet.\n",
        "* Também adicione o `logprior` a essa soma para obter o sentimento previsto daquele tweet.\n",
        "\n",
        "$p = \\text{logprior} + \\sum_i^N (\\text{loglikelihood}_i)$\n",
        "\n",
        "---\n",
        "\n",
        "#### Observação\n",
        "\n",
        "Note que calculamos o prior (logprior) a partir dos dados de treino, e que os dados de treino estão igualmente divididos entre rótulos positivos e negativos (4000 tweets positivos e 4000 tweets negativos). Isso significa que a razão entre positivos e negativos é 1, e portanto o `logprior` é 0.\n",
        "\n",
        "O valor `0.0` significa que, ao adicionarmos o `logprior` à `loglikelihood`, estamos apenas somando zero. No entanto, lembre-se de **sempre incluir o logprior**, pois, quando os dados **não estiverem perfeitamente balanceados**, o logprior terá um valor diferente de zero.\n"
      ],
      "metadata": {
        "id": "Nn5zxzXhFxYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_bayes_predicao(tweet, logprior, loglikelihood):\n",
        "    '''\n",
        "    Entrada:\n",
        "        tweet: uma string\n",
        "        logprior: um número\n",
        "        loglikelihood: um dicionário que mapeia palavras para números\n",
        "    Saída:\n",
        "        p: a soma de todas as verossimilhanças logarítmicas de cada palavra do tweet (se encontrada no dicionário) + o logprior (um número)\n",
        "    '''\n",
        "    ### INÍCIO DO CÓDIGO (SUBSTITUA INSTÂNCIAS DE 'None' PELO SEU CÓDIGO) ###\n",
        "\n",
        "    # processa o tweet para obter uma lista de palavras\n",
        "    word_l = process_tweet(tweet)\n",
        "\n",
        "    # inicializa a probabilidade com zero\n",
        "    p = 0\n",
        "\n",
        "    # adiciona o logprior\n",
        "    p += logprior\n",
        "\n",
        "    # percorre cada palavra na lista de palavras\n",
        "    for word in word_l:\n",
        "        # verifica se a palavra existe no dicionário de loglikelihood\n",
        "        if word in loglikelihood:\n",
        "            # adiciona a verossimilhança logarítmica da palavra à probabilidade\n",
        "            p += loglikelihood[word]\n",
        "\n",
        "    ### FIM DO CÓDIGO ###\n",
        "\n",
        "    return p"
      ],
      "metadata": {
        "id": "h4HxfHOxGMh6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimente com seu próprio tweet\n",
        "my_tweet = 'She smiled .'\n",
        "p = naive_bayes_predicao(my_tweet, logprior, loglikelihood)\n",
        "print('The expected output is', p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlniLLzgGT58",
        "outputId": "137cde37-bd65-4666-c7a4-db94638c49f5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The expected output is 1.5705535492750415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implemente `test_naive_bayes`\n",
        "\n",
        "**Instruções**:\n",
        "\n",
        "* Implemente a função `test_naive_bayes` para verificar a **acurácia** de suas previsões.\n",
        "* A função recebe como entrada `test_x`, `test_y`, `log_prior` e `loglikelihood`.\n",
        "* Ela retorna a **acurácia** do seu modelo.\n",
        "* Primeiro, use a função `naive_bayes_predict` para fazer previsões para cada tweet em `test_x`.\n"
      ],
      "metadata": {
        "id": "ISqOxMWLGk5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C6 (IDENTIFICADOR ÚNICO DA CÉLULA, NÃO EDITAR)\n",
        "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
        "    \"\"\"\n",
        "    Entrada:\n",
        "        test_x: uma lista de tweets\n",
        "        test_y: os rótulos correspondentes para a lista de tweets\n",
        "        logprior: o logprior\n",
        "        loglikelihood: um dicionário com as verossimilhanças (loglikelihoods) de cada palavra\n",
        "    Saída:\n",
        "        accuracy (acurácia): (número de tweets classificados corretamente) / (número total de tweets)\n",
        "    \"\"\"\n",
        "    accuracy = 0  # retorne isso corretamente\n",
        "\n",
        "    ### INÍCIO DO CÓDIGO (SUBSTITUA AS INSTÂNCIAS DE 'None' PELO SEU CÓDIGO) ###\n",
        "    y_hats = []\n",
        "    for tweet in test_x:\n",
        "        # se a predição for > 0\n",
        "        if naive_bayes_predicao(tweet, logprior, loglikelihood) > 0:\n",
        "            # a classe prevista é 1\n",
        "            y_hat_i = 1\n",
        "        else:\n",
        "            # caso contrário, a classe prevista é 0\n",
        "            y_hat_i = 0\n",
        "\n",
        "        # adicione a classe prevista à lista y_hats\n",
        "        y_hats.append(y_hat_i)\n",
        "\n",
        "    # o erro é a média dos valores absolutos das diferenças entre y_hats e test_y\n",
        "    error = np.mean(np.absolute(y_hats - test_y))\n",
        "\n",
        "    # A acurácia é 1 menos o erro\n",
        "    accuracy = 1 - error\n",
        "\n",
        "    ### FIM DO CÓDIGO ###\n",
        "\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "lcK4qXTdGnDn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Naive Bayes accuracy = %0.4f\" %\n",
        "      (test_naive_bayes(test_x, test_y, logprior, loglikelihood)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JwaXYCBGw2H",
        "outputId": "1a129d13-63ee-47b4-f712-55449dfdeef9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy = 0.9940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
        "    # print( '%s -> %f' % (tweet, naive_bayes_predict(tweet, logprior, loglikelihood)))\n",
        "    p = naive_bayes_predicao(tweet, logprior, loglikelihood)\n",
        "#     print(f'{tweet} -> {p:.2f} ({p_category})')\n",
        "    print(f'{tweet} -> {p:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjUm5GQMG2Iv",
        "outputId": "b3564ab5-acbd-4392-cf9a-809282630f2b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am happy -> 2.15\n",
            "I am bad -> -1.30\n",
            "this movie should have been great. -> 2.14\n",
            "great -> 2.13\n",
            "great great -> 4.27\n",
            "great great great -> 6.40\n",
            "great great great great -> 8.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_tweet = 'you are bad :('\n",
        "naive_bayes_predicao(my_tweet, logprior, loglikelihood)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV0D8c_EG7gI",
        "outputId": "37579880-2016-40d9-8c04-67afe441e9c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(-8.808571266641943)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 4: Filtrar palavras por razão entre contagens positivas e negativas\n",
        "\n",
        "* Algumas palavras aparecem mais frequentemente em tweets positivos do que outras, podendo ser consideradas \"mais positivas\". Da mesma forma, outras podem ser consideradas mais negativas.\n",
        "\n",
        "* Uma maneira de definir o nível de positividade ou negatividade, sem calcular a verossimilhança (log likelihood), é comparar a frequência positiva e negativa da palavra.\n",
        "\n",
        "  * Observe que também podemos usar os cálculos de log likelihood para comparar a positividade ou negatividade relativa das palavras.\n",
        "\n",
        "* Podemos calcular a razão entre as frequências positivas e negativas de uma palavra:\n",
        "\n",
        "  $\\text{razão} = \\frac{\\text{contagem positiva} + 1}{\\text{contagem negativa} + 1}$\n",
        "\n",
        "* Uma vez que podemos calcular essas razões, também conseguimos filtrar um subconjunto de palavras que tenham uma razão mínima de positividade/negatividade ou maior.\n",
        "\n",
        "* De forma semelhante, podemos filtrar palavras com uma razão máxima de positividade/negatividade ou menor (palavras que são pelo menos tão negativas, ou até mais negativas, do que um determinado limite).\n",
        "\n",
        "---\n",
        "\n",
        "### Implemente `get_ratio()`\n",
        "\n",
        "* Dado o dicionário `freqs` com as palavras, e uma palavra específica:\n",
        "\n",
        "  * Use `lookup(freqs, word, 1)` para obter a contagem positiva da palavra.\n",
        "  * Use também `lookup(freqs, word, 0)` para obter a contagem negativa da palavra.\n",
        "* Calcule a razão entre a contagem positiva e negativa com a fórmula:\n",
        "\n",
        "$\\text{razão} = \\frac{\\text{palavras positivas} + 1}{\\text{palavras negativas} + 1}$\n",
        "\n",
        "Onde `palavras positivas` e `palavras negativas` são as frequências da palavra nas respectivas classes.\n",
        "\n",
        "---\n",
        "\n",
        "#### Exemplo de tabela:\n",
        "\n",
        "| **Palavras** | Contagem Positiva | Contagem Negativa |\n",
        "| ------------ | ----------------- | ----------------- |\n",
        "| glad         | 41                | 2                 |\n",
        "| arriv        | 57                | 4                 |\n",
        "| :(           | 1                 | 3663              |\n",
        "| :-(          | 0                 | 378               |\n"
      ],
      "metadata": {
        "id": "IyAHskgoHDua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ratio(freqs, word):\n",
        "    '''\n",
        "    Entrada:\n",
        "        freqs: dicionário contendo as palavras\n",
        "\n",
        "    Saída: um dicionário com as chaves 'positive' (positiva), 'negative' (negativa) e 'ratio' (razão).\n",
        "        Exemplo: {'positive': 10, 'negative': 20, 'ratio': 0.5}\n",
        "    '''\n",
        "    pos_neg_ratio = {'positive': 0, 'negative': 0, 'ratio': 0.0}\n",
        "\n",
        "    ### INÍCIO DO CÓDIGO ###\n",
        "    # usa a função lookup() para encontrar a contagem positiva da palavra (indicada pelo inteiro 1)\n",
        "    pos_neg_ratio['positive'] = lookup(freqs, word, 1)\n",
        "\n",
        "    # usa a função lookup() para encontrar a contagem negativa da palavra (indicada pelo inteiro 0)\n",
        "    pos_neg_ratio['negative'] = lookup(freqs, word, 0)\n",
        "\n",
        "    # calcula a razão entre as contagens positivas e negativas da palavra\n",
        "    pos_neg_ratio['ratio'] = (pos_neg_ratio['positive'] + 1) / (pos_neg_ratio['negative'] + 1)\n",
        "    ### FIM DO CÓDIGO ###\n",
        "\n",
        "    return pos_neg_ratio\n"
      ],
      "metadata": {
        "id": "tirB8PY2HGeS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ratio(freqs, 'happi')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzYVvQcYHSdU",
        "outputId": "3ed8c2c4-6327-4e00-d809-7ebd92be855f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'positive': 161, 'negative': 18, 'ratio': 8.526315789473685}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui está a tradução da instrução para implementar a função `get_words_by_threshold`:\n",
        "\n",
        "---\n",
        "\n",
        "### Implemente `get_words_by_threshold(freqs, label, threshold)`\n",
        "\n",
        "* Se definirmos o `label` como `1`, então iremos buscar por todas as palavras cuja **razão entre contagens positiva/negativa** seja **igual ou maior** que o limiar (`threshold`).\n",
        "* Se definirmos o `label` como `0`, então iremos buscar por todas as palavras cuja **razão entre contagens positiva/negativa** seja **igual ou menor** que o limiar (`threshold`).\n",
        "* Use a função `get_ratio()` para obter um dicionário contendo a contagem positiva, a contagem negativa e a razão positiva/negativa de uma palavra.\n",
        "* Adicione um dicionário a uma lista, onde a **chave** é a **palavra** e o **valor** é o dicionário `pos_neg_ratio` retornado pela função `get_ratio()`.\n",
        "\n",
        "Um exemplo de par chave-valor seria:\n",
        "\n",
        "```python\n",
        "{'happi':  # palavra\n",
        "    {'positive': 10, 'negative': 20, 'ratio': 0.5}  # estatísticas da palavra\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "9CmhT2KhHZDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_words_by_threshold(freqs, label, threshold):\n",
        "    '''\n",
        "    Entrada:\n",
        "        freqs: dicionário de palavras\n",
        "        label: 1 para positivo, 0 para negativo\n",
        "        threshold (limiar): razão que será usada como critério para incluir uma palavra no dicionário retornado\n",
        "\n",
        "    Saída:\n",
        "        word_set: dicionário contendo a palavra e informações sobre sua contagem positiva, contagem negativa e razão positiva/negativa.\n",
        "        exemplo de par chave-valor:\n",
        "        {'happi':\n",
        "            {'positive': 10, 'negative': 20, 'ratio': 0.5}\n",
        "        }\n",
        "    '''\n",
        "    word_list = {}\n",
        "\n",
        "    ### INÍCIO DO CÓDIGO ###\n",
        "    for key in freqs.keys():\n",
        "        word, _ = key\n",
        "\n",
        "        # obtém a razão positivo/negativo da palavra\n",
        "        pos_neg_ratio = get_ratio(freqs, word)\n",
        "\n",
        "        # se o rótulo for 1 (positivo) e a razão for maior ou igual ao limiar...\n",
        "        if label == 1 and pos_neg_ratio['ratio'] >= threshold:\n",
        "\n",
        "            # adiciona a razão ao dicionário\n",
        "            word_list[word] = pos_neg_ratio\n",
        "\n",
        "        # se o rótulo for 0 (negativo) e a razão for menor ou igual ao limiar...\n",
        "        elif label == 0 and pos_neg_ratio['ratio'] <= threshold:\n",
        "            # adiciona a razão ao dicionário\n",
        "            word_list[word] = pos_neg_ratio\n",
        "\n",
        "        # caso contrário, não inclui a palavra (não faz nada)\n",
        "\n",
        "    ### FIM DO CÓDIGO ###\n",
        "    return word_list\n"
      ],
      "metadata": {
        "id": "jQzTq-vEHcAl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testando função\n",
        "get_words_by_threshold(freqs, label=0, threshold=0.05)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B170IqFjHtw4",
        "outputId": "46463a06-eb51-4e0e-a204-3ebc380918d2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{':(': {'positive': 1, 'negative': 3663, 'ratio': 0.0005458515283842794},\n",
              " ':-(': {'positive': 0, 'negative': 378, 'ratio': 0.002638522427440633},\n",
              " 'zayniscomingbackonjuli': {'positive': 0, 'negative': 19, 'ratio': 0.05},\n",
              " '26': {'positive': 0, 'negative': 20, 'ratio': 0.047619047619047616},\n",
              " '>:(': {'positive': 0, 'negative': 43, 'ratio': 0.022727272727272728},\n",
              " 'lost': {'positive': 0, 'negative': 19, 'ratio': 0.05},\n",
              " '♛': {'positive': 0, 'negative': 210, 'ratio': 0.004739336492890996},\n",
              " '》': {'positive': 0, 'negative': 210, 'ratio': 0.004739336492890996},\n",
              " 'beli̇ev': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776},\n",
              " 'wi̇ll': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776},\n",
              " 'justi̇n': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776},\n",
              " 'ｓｅｅ': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776},\n",
              " 'ｍｅ': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776}}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_words_by_threshold(freqs, label=1, threshold=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvJVsA_QH4AA",
        "outputId": "4570bb0c-e79f-409d-89b3-c8d7d0562d7d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'followfriday': {'positive': 23, 'negative': 0, 'ratio': 24.0},\n",
              " 'commun': {'positive': 27, 'negative': 1, 'ratio': 14.0},\n",
              " ':)': {'positive': 2847, 'negative': 2, 'ratio': 949.3333333333334},\n",
              " 'flipkartfashionfriday': {'positive': 16, 'negative': 0, 'ratio': 17.0},\n",
              " ':d': {'positive': 498, 'negative': 0, 'ratio': 499.0},\n",
              " ':p': {'positive': 104, 'negative': 0, 'ratio': 105.0},\n",
              " 'influenc': {'positive': 16, 'negative': 0, 'ratio': 17.0},\n",
              " ':-)': {'positive': 543, 'negative': 0, 'ratio': 544.0},\n",
              " \"here'\": {'positive': 20, 'negative': 0, 'ratio': 21.0},\n",
              " 'youth': {'positive': 14, 'negative': 0, 'ratio': 15.0},\n",
              " 'bam': {'positive': 44, 'negative': 0, 'ratio': 45.0},\n",
              " 'warsaw': {'positive': 44, 'negative': 0, 'ratio': 45.0},\n",
              " 'shout': {'positive': 11, 'negative': 0, 'ratio': 12.0},\n",
              " ';)': {'positive': 22, 'negative': 0, 'ratio': 23.0},\n",
              " 'stat': {'positive': 51, 'negative': 0, 'ratio': 52.0},\n",
              " 'arriv': {'positive': 57, 'negative': 4, 'ratio': 11.6},\n",
              " 'via': {'positive': 60, 'negative': 1, 'ratio': 30.5},\n",
              " 'glad': {'positive': 41, 'negative': 2, 'ratio': 14.0},\n",
              " 'blog': {'positive': 27, 'negative': 0, 'ratio': 28.0},\n",
              " 'fav': {'positive': 11, 'negative': 0, 'ratio': 12.0},\n",
              " 'fback': {'positive': 26, 'negative': 0, 'ratio': 27.0},\n",
              " 'pleasur': {'positive': 10, 'negative': 0, 'ratio': 11.0}}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_tweet = 'I am happy because I am learning :)'\n",
        "\n",
        "p = naive_bayes_predicao(my_tweet, logprior, loglikelihood)\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmuCxVrQH-iZ",
        "outputId": "51fb5d33-a088-438f-e077-2b85074bbcb4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.564346021948712\n"
          ]
        }
      ]
    }
  ]
}